import os
import re
import argparse
import pandas as pd
import time
import logging
from datetime import datetime

from mlx_lm import load, generate
from mlx_lm.sample_utils import make_sampler

from utils import extract_json_from_response

# ANSIã‚«ãƒ©ãƒ¼å®šç¾©
COLOR_GREEN = "\033[92m"
COLOR_YELLOW = "\033[93m"
COLOR_BLUE = "\033[94m"
COLOR_RED = "\033[91m"
COLOR_RESET = "\033[0m"

def load_model_and_tokenizer(model_path: str):
    """
    MLX_LMãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦è¿”ã™ã€‚
    """
    model, tokenizer = load(model_path)
    return model, tokenizer


def build_first_prompt() -> list:
    """
    1ã¤ç›®ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã—ã€chatå½¢å¼ã§è¿”ã™ã€‚
    """
    user_question = f"{LABEL['ç–¾æ‚£']}ã®æ‚£è€…ã•ã‚“ã®ä¸­ã§ã€{LABEL['å‡¦ç½®']}ãŒä½¿ã‚ã‚ŒãŸæ‚£è€…ã¯ä½•äººï¼Ÿ"

    prompt_template = f"""ä»¥ä¸‹ã¯ã¾ãšå‡ºåŠ›ä¾‹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚
å¿ƒä¸å…¨ã®æ‚£è€…ã®ä¸­ã§ã€è‚ºæ°´è…«ã®æ‚£è€…ã¯ä½•äººï¼Ÿ"ã¨ã„ã†è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«æœ€ä½é™å¿…è¦ãªåŒ»å­¦çš„ãªæ§‹é€ åŒ–é …ç›®ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚jsonå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
å›ç­”ï¼š
[
  {{
    "fieldName": "å¿ƒä¸å…¨è¨ºæ–­",
    "fieldType": "ãƒ–ãƒ¼ãƒ«å€¤",
    "description": "æ‚£è€…ãŒå¿ƒä¸å…¨ã¨è¨ºæ–­ã•ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹ (true ã¾ãŸã¯ false)",
  }},
  {{
    "fieldName": "è‚ºæ°´è…«è¨ºæ–­",
    "fieldType": "ãƒ–ãƒ¼ãƒ«å€¤",
    "description": "æ‚£è€…ãŒè‚ºæ°´è…«ã¨è¨ºæ–­ã•ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹ (true ã¾ãŸã¯ false)"
  }}
]
å‡ºåŠ›ä¾‹ã¯ã“ã“ã¾ã§ã§ã™ã€‚ç¶šã„ã¦ã€{user_question}ã¨ã„ã†è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«æœ€ä½é™å¿…è¦ãªåŒ»å­¦çš„ãªæ§‹é€ åŒ–é …ç›®ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚jsonã¨ã—ã¦parseã§ãã‚‹ã‚ˆã†ã«jsonå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚å›ç­”ã®jsonã®ã¿ã‚’1å›ã ã‘å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
å›ç­”ï¼š"""

    formatted_prompt = (
        "ã‚ãªãŸã¯åŒ»ç™‚ã«é–¢ã™ã‚‹è³ªå•ã«ç­”ãˆã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®è³ªå•æ–‡ã‚’æ§‹é€ åŒ–ã—ã¦ãã ã•ã„ã€‚\n"
        + prompt_template
    )
    return formatted_prompt


def run_inference(model, tokenizer, chat: list, temp=0.0, top_p=0.95) -> str:
    """
    å¼•æ•°ã®chatã‚’ã‚‚ã¨ã«ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’è¡Œã„ã€å¿œç­”æ–‡å­—åˆ—ã‚’è¿”ã™ã€‚
    """
    # chat_str = json.dumps(chat, ensure_ascii=False, indent=2)
    sampler = make_sampler(temp=temp, top_p=top_p)
    # print(f"chat_str: \n----------\nğŸ{chat_str}ğŸ\n----------")
    response = generate(model, tokenizer, prompt=chat, verbose=False, sampler=sampler)
    return response


def extract_text_before_endoftext(text: str) -> str:
    """
    æ–‡å­—åˆ—ã‹ã‚‰ <|endoftext|> ä»¥å‰ã®æ–‡å­—åˆ—ã‚’æŠ½å‡ºã—ã¦è¿”ã™
    """
    pattern = r"(.*?)<\|endoftext\|>"
    match = re.search(pattern, text, re.DOTALL)
    return match.group(1) if match else text


def save_response_to_file(response: str, output_file: str, model_path: str):
    """
    å¿œç­”æ–‡å­—åˆ—ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€
    """
    with open(os.path.join(LOG_DIR, output_file), "w", encoding="utf-8") as f:
        f.write(f"{model_path}\n\n{response}")


def build_second_prompt(structured_question: str, document_text: str) -> list:
    """
    structured_questionï¼ˆ1ã¤ç›®ã®æ¨è«–ã§å¾—ã‚‰ã‚ŒãŸjsonçš„ãªå‡ºåŠ›ï¼‰ã¨
    ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆã‚’çµ„ã¿åˆã‚ã›ã¦2ã¤ç›®ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿”ã™ã€‚
    """
    prompt_template = (
        "json_for_structuring:\n"
        f"{structured_question}\n\n"
        "ä¸Šè¨˜ã®jsonã«å¾“ã£ã¦ã€ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹é€ åŒ–ã—ã¦ãã ã•ã„ã€‚\n"
        f"ehr_data:\n{document_text}\n\n"
        "== jsonå‡ºåŠ›ã®ä¾‹ ==\n"
        # ä¾‹ã‚’é…åˆ—ã§ã¯ãªãã€Œ1ã¤ã®JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€ã«å¤‰æ›´
        "```json\n"
        "{\n"
        '  "å¿ƒåœæ­¢è¨ºæ–­": {\n'
        '    "value": false,\n'
        '    "reason": "ç†ç”±ã‚’æ›¸ã"\n'
        "  },\n"
        '  "ECMOä½¿ç”¨": {\n'
        '    "value": false,\n'
        '    "reason": "ç†ç”±ã‚’æ›¸ã"\n'
        "  }\n"
        "}\n"
        "```"
        "\n"
        "== jsonå‡ºåŠ›ã®ä¾‹ ==\n\n"
        "json_for_structuringã®ãã‚Œãã‚Œã«ã¤ã„ã¦ã€ehr_dataã«è©²å½“ã™ã‚‹ã‹ã©ã†ã‹ã‚’trueã‹falseã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n"
        "ã¾ãŸã€ãã®ç†ç”±ã‚‚æ›¸ã„ã¦ãã ã•ã„ã€‚\n"
        "å›ç­”ã¯ä¸Šã®ä¾‹ã®ã‚ˆã†ã«ã€ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ãŒ1ã¤ã®JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ãªã‚‹ã‚ˆã†ã«å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n"
        "å›ç­”:"
    )

    formatted_prompt = (
        "ã‚ãªãŸã¯åŒ»ç™‚ã«é–¢ã™ã‚‹è³ªå•ã«ç­”ãˆã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®è³ªå•æ–‡ã‚’æ§‹é€ åŒ–ã—ã¦ãã ã•ã„ã€‚\n"
        + prompt_template
    )
    return formatted_prompt


def make_document_text(df_one_document: pd.DataFrame) -> str:
    """
    df_one_documentã‹ã‚‰å„é …ç›®ã‚’ãƒ†ã‚­ã‚¹ãƒˆæ•´å½¢ã—ã¦è¿”ã™ã€‚
    """
    return f"""# ä¸»è¨´
{df_one_document['ä¸»è¨´']}

# å…¥é™¢ã¾ã§ã®çµŒé
{df_one_document['å…¥é™¢ã¾ã§ã®çµŒé']}

# å…¥é™¢ä¸­çµŒé
{df_one_document['å…¥é™¢ä¸­çµŒé']}

# é€€é™¢æ™‚æ‰€è¦‹
{df_one_document['é€€é™¢æ™‚æ‰€è¦‹']}"""


def check_all_true(bool_list):
    """
    ãƒ–ãƒ¼ãƒ«å€¤ãƒªã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã€å…¨ã¦Trueãªã‚‰Trueã€1ã¤ã§ã‚‚FalseãŒã‚ã‚Œã°Falseã‚’è¿”ã™ã€‚
    """
    return all(bool_list)


def main():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°ã€‚checkpointæ©Ÿèƒ½ã‚’å…¨ã¦å‰Šé™¤ã—ã€æ¯å› result_df ã‚’ä¿å­˜ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£ã€‚
    """
    total_start_time = time.time()

    logger.info("===== START MAIN =====")
    logger.info(f"Using model: {MODEL_PATH}")
    print(f"{COLOR_BLUE}--- Using model: {MODEL_PATH} ---{COLOR_RESET}")
    print()

    # ---------------------------------------------------------------------
    # 1) ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’ãƒ­ãƒ¼ãƒ‰
    # ---------------------------------------------------------------------
    step1_start = time.time()
    text_1_1 = "[STEP1] Loading model and tokenizer ..."
    logger.info(text_1_1)
    print(f"{COLOR_BLUE}--- {text_1_1} ---{COLOR_RESET}")
    model, tokenizer = load_model_and_tokenizer(MODEL_PATH)
    step1_end = time.time()
    text_1_2 = f"[STEP1] Finished in {step1_end - step1_start:.3f} seconds\n"
    logger.info(text_1_2)
    print(f"{COLOR_BLUE}--- {text_1_2} ---{COLOR_RESET}")

    # ---------------------------------------------------------------------
    # 2) æœ€åˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã—ã€ãƒ¢ãƒ‡ãƒ«ã«å•ã„åˆã‚ã›
    # ---------------------------------------------------------------------
    step2_start = time.time()
    text_2_1 = "[STEP2] Building first prompt and running inference ..."
    logger.info(text_2_1)
    print(f"{COLOR_BLUE}--- {text_2_1} ---{COLOR_RESET}")
    chat_first = build_first_prompt()
    response1 = run_inference(model, tokenizer, chat_first, temp=0.0, top_p=0.95)
    # print(f"response1: \n----------\nğŸ{response1}ğŸ\n----------")
    response1 = extract_text_before_endoftext(response1)
    text_2_2 = f"[STEP2] First inference result:\n{response1}"
    logger.info(text_2_2)
    print(f"{COLOR_BLUE}--- {text_2_2} ---{COLOR_RESET}")
    step2_end = time.time()
    text_2_3 = f"[STEP2] Finished in {step2_end - step2_start:.3f} seconds\n"
    logger.info(text_2_3)
    print(f"{COLOR_BLUE}--- {text_2_3} ---{COLOR_RESET}")

    # ---------------------------------------------------------------------
    # 3) å¿œç­”ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ (ä»»æ„)
    # ---------------------------------------------------------------------
    step3_start = time.time()
    text_3_1 = "[STEP3] Saving first inference result to file ..."
    logger.info(text_3_1)
    print(f"{COLOR_BLUE}--- {text_3_1} ---{COLOR_RESET}")
    save_response_to_file(response1, "response_v01.txt", MODEL_PATH)
    step3_end = time.time()
    text_3_2 = f"[STEP3] Finished in {step3_end - step3_start:.3f} seconds\n"
    logger.info(text_3_2)
    print(f"{COLOR_BLUE}--- {text_3_2} ---{COLOR_RESET}")

    # ---------------------------------------------------------------------
    # 4) CSVã®èª­ã¿è¾¼ã¿ -> ãƒ«ãƒ¼ãƒ—ã§2ã¤ç›®ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆãƒ»æ¨è«–
    # ---------------------------------------------------------------------
    step4_start = time.time()
    logger.info("[STEP4] Reading CSV and looping over rows ...")

    df = pd.read_csv("40_result_df.csv")
    # df = df[(df['ã‚«ãƒ«ãƒ†No'] >= 756) & (df['ã‚«ãƒ«ãƒ†No'] <= 758)]
    # df = df[df['ã‚«ãƒ«ãƒ†No'] >= 710]
    # df = df[df[f"{LABEL['ç–¾æ‚£']}+{LABEL['å‡¦ç½®']}"] == 1]  # æ­£è§£ãƒ‡ãƒ¼ã‚¿ãŒ1ã®ã‚‚ã®ã®ã¿ã‚’ä½¿ã†
    # df = df.iloc[18:]
    print()
    text_4_1 = f"{COLOR_YELLOW}ãƒ‡ãƒ¼ã‚¿æ•°:{COLOR_RESET} {len(df)}"
    print(text_4_1)
    logger.info(text_4_1)
    text_4_2 = f"{COLOR_YELLOW}æ‚£è€…æ•°:{COLOR_RESET} {df['æ‚£è€…No'].nunique()}"
    print(text_4_2)
    logger.info(text_4_2)
    print()

    result = []
    make_bool_flase_list = []

    elapsed_time_list = []
    for idx in range(len(df)):
        iter_start_time = time.time()

        calte_no = df.iloc[idx]["ã‚«ãƒ«ãƒ†No"]
        df_one_document = df.iloc[idx]

        label = df_one_document.get(f"{LABEL['ç–¾æ‚£']}+{LABEL['å‡¦ç½®']}", False)
        str_one_document = make_document_text(df_one_document)

        chat_second = build_second_prompt(structured_question=response1, document_text=str_one_document)
        response2_raw = run_inference(model, tokenizer, chat_second, temp=0.0, top_p=0.95)
        response2 = extract_text_before_endoftext(response2_raw)

        parsed_json = extract_json_from_response(response2)
        json_parse_success = ("error" not in parsed_json)

        # chat_second_str = json.dumps(chat_second, ensure_ascii=False, indent=2)
        # print(f"chat_second_str: \n----------\nğŸ{chat_second_str}ğŸ\n----------")
        # print(f"response2_raw: \n----------\nğŸ{response2_raw}ğŸ\n----------")
        # print(f"response2: \n----------\nğŸ{response2}ğŸ\n----------")
        # print(f"parsed_json: \n----------\nğŸ{parsed_json}ğŸ\n----------")
        # print(f"json_parse_success: \n----------\nğŸ{json_parse_success}ğŸ\n----------")
        # exit()

        try:
            bool_list = []
            for key in parsed_json.keys():
                val = parsed_json[key]
                if isinstance(val, dict) and ("value" in val):
                    bool_list.append(val["value"])
                elif isinstance(val, bool):
                    bool_list.append(val)
                else:
                    bool_list.append(False)

            result_all_true = check_all_true(bool_list)
        except Exception:
            make_bool_flase_list.append([idx, df_one_document['æ‚£è€…No']])
            print(f"ğŸ{parsed_json}ğŸ")
            continue

        print(f"{COLOR_BLUE}--- [Iteration {idx}/{len(df)}] ã‚«ãƒ«ãƒ†No: {calte_no} processed ---{COLOR_RESET}")
        parse_success_msg = f"{COLOR_GREEN}SUCCESS{COLOR_RESET}" if json_parse_success else f"{COLOR_RED}FAILED{COLOR_RESET}"
        print(f"{COLOR_YELLOW}json_parse_success:{COLOR_RESET} {parse_success_msg}")
        result_str = "æ­£è§£" if result_all_true == label else "ä¸æ­£è§£"
        output_str = f"{COLOR_YELLOW}ğŸcheck_all_true ã®çµæœ:{COLOR_RESET} {bool_list} -> {result_all_true} | {COLOR_YELLOW}æ­£è§£ãƒ‡ãƒ¼ã‚¿:{COLOR_RESET} {bool(label)}"
        output_str += f" | {COLOR_YELLOW}çµæœ:{COLOR_RESET} {COLOR_RED if result_all_true != label else COLOR_GREEN}{result_str}{COLOR_RESET}"
        print(output_str)

        logger.info(f"[Iteration {idx+1}/{len(df)}] response2: ğŸ{response2}ğŸ")
        logger.info(f"[Iteration {idx+1}/{len(df)}] parsed_json: ğŸ{parsed_json}ğŸ")
        logger.info(f"[Iteration {idx+1}/{len(df)}] JSON parse success => ğŸ{json_parse_success}ğŸ")
        logger.info(f"[Iteration {idx+1}/{len(df)}] check_all_true => ğŸ{output_str}ğŸ")

        iter_end_time = time.time()
        elapsed_time = iter_end_time - iter_start_time
        elapsed_time_list.append(elapsed_time)
        logger.info(f"[Iteration {idx+1}/{len(df)}] took {elapsed_time:.2f} sec, average {sum(elapsed_time_list)/len(elapsed_time_list):.2f} sec\n")
        print(f"{COLOR_BLUE}Took {elapsed_time:.2f} sec, average {sum(elapsed_time_list)/len(elapsed_time_list):.2f} sec{COLOR_RESET}")

        # çµæœã‚’æ ¼ç´
        result.append((
            calte_no,
            response2,
            parsed_json,
            bool_list[0] if len(bool_list) > 0 else False,
            bool_list[1] if len(bool_list) > 1 else False,
            result_all_true,
            label,
            (result_all_true == label),
            json_parse_success
        ))

        # æ¯å›result_dfã‚’ä¿å­˜
        result_df = pd.DataFrame(
            result,
            columns=[
                "ã‚«ãƒ«ãƒ†No",
                "response2",
                "parsed_json",
                "bool_list_0",
                "bool_list_1",
                "result_all_true",
                "label",
                "result_all_true_eq_label",
                "json_parse_success",
            ],
        )
        result_df.to_csv(f"{LOG_DIR}/result_df.csv", index=False)

        # break  # <- å¿…è¦ã«å¿œã˜ã¦ãƒ«ãƒ¼ãƒ—ã‚’é€”ä¸­ã§åˆ‡ã‚ŠãŸã„å ´åˆã«ä½¿ç”¨

    step4_end = time.time()
    logger.info(f"[STEP4] All loop done in {step4_end - step4_start:.3f} seconds\n")

    total_end_time = time.time()
    logger.info(f"=== TOTAL processing time: {total_end_time - total_start_time:.3f} seconds ===")
    logger.info("===== END MAIN =====\n")

    make_bool_flase_df = pd.DataFrame(make_bool_flase_list, columns=["idx", "æ‚£è€…No"])
    make_bool_flase_df.to_csv(f"{LOG_DIR}/make_bool_flase_df.csv", index=False)

    print(f"{COLOR_GREEN}=== å…¨ä½“å‡¦ç†æ™‚é–“: {(total_end_time - total_start_time)/60:.2f} åˆ† ==={COLOR_RESET}")


if __name__ == "__main__":
    global LABEL
    global LOG_DIR
    global LOG_FILENAME
    global MODEL_PATH

    parser = argparse.ArgumentParser(description="ãƒ©ãƒ™ãƒ«ã‚’æŒ‡å®šã—ã¦å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    parser.add_argument('--label1', type=str, required=True, help="ç–¾æ‚£ã®ãƒ©ãƒ™ãƒ«")
    parser.add_argument('--label2', type=str, required=True, help="å‡¦ç½®ã®ãƒ©ãƒ™ãƒ«")
    args = parser.parse_args()
    LABEL = {"ç–¾æ‚£": args.label1, "å‡¦ç½®": args.label2}
    print(f"{COLOR_RED}LABEL: {LABEL}{COLOR_RESET}")

    datetime_str = datetime.now().strftime("%Y%m%d%H%M%S")
    LOG_DIR = f"logs/log_{datetime_str}_Preferred-Qwen-72B-8bit_{LABEL['ç–¾æ‚£']}+{LABEL['å‡¦ç½®']}"
    os.makedirs(LOG_DIR, exist_ok=True)

    LOG_FILENAME = datetime.now().strftime(f"{LOG_DIR}/log.txt")

    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)

    file_handler = logging.FileHandler(LOG_FILENAME, mode="w", encoding="utf-8")
    file_handler.setLevel(logging.INFO)
    logger.addHandler(file_handler)

    MODEL_PATH = "../../convert2mlx/Preferred-MedLLM-Qwen-72B-mlx-8bit"
    main()