import os
import re
import json
import pandas as pd
import time
import logging
import argparse
import glob
from datetime import datetime

from mlx_lm import load, generate
from mlx_lm.sample_utils import make_sampler

from utils import extract_json_from_response

# ANSIã‚«ãƒ©ãƒ¼å®šç¾©
COLOR_GREEN = "\033[92m"
COLOR_YELLOW = "\033[93m"
COLOR_BLUE = "\033[94m"
COLOR_RED = "\033[91m"
COLOR_RESET = "\033[0m"

# ---------------------
# ãƒ­ã‚°è¨­å®š
# ---------------------
# æ—¥æ™‚ã‚’å«ã‚“ã ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å (ä¾‹: log_202501100932.txt)

def load_model_and_tokenizer(model_path: str):
    """
    MLX_LMãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦è¿”ã™ã€‚
    """
    model, tokenizer = load(model_path)
    return model, tokenizer


def build_first_prompt() -> list:
    """
    1ã¤ç›®ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã—ã€chatå½¢å¼ã§è¿”ã™ã€‚
    """
    user_question = f"{LABEL['ç–¾æ‚£']}ã®æ‚£è€…ã•ã‚“ã®ä¸­ã§ã€{LABEL['å‡¦ç½®']}ãŒä½¿ã‚ã‚ŒãŸæ‚£è€…ã¯ä½•äººï¼Ÿ"

    prompt_template = f"""ä»¥ä¸‹ã¯ã¾ãšå‡ºåŠ›ä¾‹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚
å¿ƒä¸å…¨ã®æ‚£è€…ã®ä¸­ã§ã€è‚ºæ°´è…«ã®æ‚£è€…ã¯ä½•äººï¼Ÿ"ã¨ã„ã†è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«æœ€ä½é™å¿…è¦ãªåŒ»å­¦çš„ãªæ§‹é€ åŒ–é …ç›®ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚jsonå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
å›ç­”ï¼š
[
  {{
    "fieldName": "å¿ƒä¸å…¨è¨ºæ–­",
    "fieldType": "ãƒ–ãƒ¼ãƒ«å€¤",
    "description": "æ‚£è€…ãŒå¿ƒä¸å…¨ã¨è¨ºæ–­ã•ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹ (true ã¾ãŸã¯ false)",
  }},
  {{
    "fieldName": "è‚ºæ°´è…«è¨ºæ–­",
    "fieldType": "ãƒ–ãƒ¼ãƒ«å€¤",
    "description": "æ‚£è€…ãŒè‚ºæ°´è…«ã¨è¨ºæ–­ã•ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹ (true ã¾ãŸã¯ false)"
  }}
]
å‡ºåŠ›ä¾‹ã¯ã“ã“ã¾ã§ã§ã™ã€‚ç¶šã„ã¦ã€{user_question}ã¨ã„ã†è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«æœ€ä½é™å¿…è¦ãªåŒ»å­¦çš„ãªæ§‹é€ åŒ–é …ç›®ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚jsonã¨ã—ã¦parseã§ãã‚‹ã‚ˆã†ã«jsonå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚å›ç­”ã®jsonã®ã¿ã‚’1å›ã ã‘å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
å›ç­”ï¼š"""

    formatted_prompt = (
        "ã‚ãªãŸã¯åŒ»ç™‚ã«é–¢ã™ã‚‹è³ªå•ã«ç­”ãˆã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®è³ªå•æ–‡ã‚’æ§‹é€ åŒ–ã—ã¦ãã ã•ã„ã€‚\n"
        + prompt_template
    )

    chat = [
        {"role": "system", "content": "ä»¥ä¸‹ã¯ã€ã‚¿ã‚¹ã‚¯ã‚’èª¬æ˜ã™ã‚‹æŒ‡ç¤ºã§ã™ã€‚è¦æ±‚ã‚’é©åˆ‡ã«æº€ãŸã™å¿œç­”ã‚’æ›¸ããªã•ã„ã€‚"},
        {"role": "user", "content": formatted_prompt},
    ]
    return chat


def run_inference(model, tokenizer, chat: list, temp=0.0, top_p=1.0) -> str:
    """
    å¼•æ•°ã®chatã‚’ã‚‚ã¨ã«ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’è¡Œã„ã€å¿œç­”æ–‡å­—åˆ—ã‚’è¿”ã™ã€‚
    """
    chat_str = json.dumps(chat, ensure_ascii=False, indent=2)
    sampler = make_sampler(temp=temp, top_p=top_p)
    response = generate(model, tokenizer, prompt=chat_str, verbose=False, sampler=sampler)
    return response


def extract_text_before_endoftext(text: str) -> str:
    """
    æ–‡å­—åˆ—ã‹ã‚‰ <|endoftext|> ä»¥å‰ã®æ–‡å­—åˆ—ã‚’æŠ½å‡ºã—ã¦è¿”ã™
    """
    pattern = r"(.*?)<\|endoftext\|>"
    match = re.search(pattern, text, re.DOTALL)
    return match.group(1) if match else text


def save_response_to_file(response: str, output_file: str, model_path: str):
    """
    å¿œç­”æ–‡å­—åˆ—ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€
    """
    with open(os.path.join(LOG_DIR, output_file), "w", encoding="utf-8") as f:
        f.write(f"{model_path}\n\n{response}")


def build_second_prompt(structured_question: str, document_text: str, retry_info: str = "") -> list:
    """
    structured_questionï¼ˆ1ã¤ç›®ã®æ¨è«–ã§å¾—ã‚‰ã‚ŒãŸjsonçš„ãªå‡ºåŠ›ï¼‰ã¨
    ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆã‚’çµ„ã¿åˆã‚ã›ã¦2ã¤ç›®ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿”ã™ã€‚
    """
    retry_section = f"\n\n{retry_info}" if retry_info else ""
    
    prompt_template = (
        "json_for_structuring:\n"
        f"{structured_question}\n\n"
        "ä¸Šè¨˜ã®jsonã«å¾“ã£ã¦ã€ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹é€ åŒ–ã—ã¦ãã ã•ã„ã€‚\n"
        f"ehr_data:\n{document_text}\n\n"
        f"{retry_section}"
        "== jsonå‡ºåŠ›ã®ä¾‹ ==\n"
        # ä¾‹ã‚’é…åˆ—ã§ã¯ãªãã€Œ1ã¤ã®JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€ã«å¤‰æ›´
        "```json\n"
        "{\n"
        '  "å¿ƒåœæ­¢è¨ºæ–­": {\n'
        '    "value": false,\n'
        '    "reason": "ç†ç”±ã‚’æ›¸ã"\n'
        "  },\n"
        '  "ECMOä½¿ç”¨": {\n'
        '    "value": false,\n'
        '    "reason": "ç†ç”±ã‚’æ›¸ã"\n'
        "  }\n"
        "}\n"
        "```"
        "\n"
        "== jsonå‡ºåŠ›ã®ä¾‹ ==\n\n"
        "json_for_structuringã®ãã‚Œãã‚Œã«ã¤ã„ã¦ã€ehr_dataã«è©²å½“ã™ã‚‹ã‹ã©ã†ã‹ã‚’trueã‹falseã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n"
        "ã¾ãŸã€ãã®ç†ç”±ã‚‚æ›¸ã„ã¦ãã ã•ã„ã€‚\n"
        "å›ç­”ã¯ä¸Šã®ä¾‹ã®ã‚ˆã†ã«ã€ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ãŒ1ã¤ã®JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ãªã‚‹ã‚ˆã†ã«å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n"
        "å›ç­”:"
    )

    formatted_prompt = (
        "ã‚ãªãŸã¯åŒ»ç™‚ã«é–¢ã™ã‚‹è³ªå•ã«ç­”ãˆã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®è³ªå•æ–‡ã‚’æ§‹é€ åŒ–ã—ã¦ãã ã•ã„ã€‚\n"
        + prompt_template
    )

    chat = [
        {"role": "system", "content": "ä»¥ä¸‹ã¯ã€ã‚¿ã‚¹ã‚¯ã‚’èª¬æ˜ã™ã‚‹æŒ‡ç¤ºã§ã™ã€‚è¦æ±‚ã‚’é©åˆ‡ã«æº€ãŸã™å¿œç­”ã‚’æ›¸ããªã•ã„ã€‚"},
        {"role": "user", "content": formatted_prompt},
    ]
    return chat


def make_document_text(txt_content: str) -> str:
    """
    txt fileã®å†…å®¹ã‚’ãã®ã¾ã¾åŒ»ç™‚è¨˜éŒ²ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦è¿”ã™ã€‚
    """
    return txt_content.strip()


def check_all_true(bool_list):
    """
    ãƒ–ãƒ¼ãƒ«å€¤ãƒªã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã€å…¨ã¦Trueãªã‚‰Trueã€1ã¤ã§ã‚‚FalseãŒã‚ã‚Œã°Falseã‚’è¿”ã™ã€‚
    """
    return all(bool_list)


def main():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°ã€‚checkpointæ©Ÿèƒ½ã‚’å…¨ã¦å‰Šé™¤ã—ã€æ¯å› result_df ã‚’ä¿å­˜ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£ã€‚
    """
    total_start_time = time.time()

    logger.info("===== START MAIN =====")
    logger.info(f"Using model: {MODEL_PATH}")
    print(f"{COLOR_BLUE}--- Using model: {MODEL_PATH} ---{COLOR_RESET}")
    print()

    # ---------------------------------------------------------------------
    # 1) ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’ãƒ­ãƒ¼ãƒ‰
    # ---------------------------------------------------------------------
    step1_start = time.time()
    text_1_1 = "[STEP1] Loading model and tokenizer ..."
    logger.info(text_1_1)
    print(f"{COLOR_BLUE}--- {text_1_1} ---{COLOR_RESET}")
    model, tokenizer = load_model_and_tokenizer(MODEL_PATH)
    step1_end = time.time()
    text_1_2 = f"[STEP1] Finished in {step1_end - step1_start:.3f} seconds\n"
    logger.info(text_1_2)
    print(f"{COLOR_BLUE}--- {text_1_2} ---{COLOR_RESET}")

    # ---------------------------------------------------------------------
    # 2) æœ€åˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã—ã€ãƒ¢ãƒ‡ãƒ«ã«å•ã„åˆã‚ã›
    # ---------------------------------------------------------------------
    step2_start = time.time()
    text_2_1 = "[STEP2] Building first prompt and running inference ..."
    logger.info(text_2_1)
    print(f"{COLOR_BLUE}--- {text_2_1} ---{COLOR_RESET}")
    chat_first = build_first_prompt()
    response1 = run_inference(model, tokenizer, chat_first, temp=0.0, top_p=1.0)
    response1 = extract_text_before_endoftext(response1)
    text_2_2 = f"[STEP2] First inference result:\n{response1}"
    logger.info(text_2_2)
    print(f"{COLOR_BLUE}--- {text_2_2} ---{COLOR_RESET}")
    step2_end = time.time()
    text_2_3 = f"[STEP2] Finished in {step2_end - step2_start:.3f} seconds\n"
    logger.info(text_2_3)
    print(f"{COLOR_BLUE}--- {text_2_3} ---{COLOR_RESET}")

    # ---------------------------------------------------------------------
    # 3) å¿œç­”ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ (ä»»æ„)
    # ---------------------------------------------------------------------
    step3_start = time.time()
    text_3_1 = "[STEP3] Saving first inference result to file ..."
    logger.info(text_3_1)
    print(f"{COLOR_BLUE}--- {text_3_1} ---{COLOR_RESET}")
    save_response_to_file(response1, "response_v01.txt", MODEL_PATH)
    step3_end = time.time()
    text_3_2 = f"[STEP3] Finished in {step3_end - step3_start:.3f} seconds\n"
    logger.info(text_3_2)
    print(f"{COLOR_BLUE}--- {text_3_2} ---{COLOR_RESET}")

    # ---------------------------------------------------------------------
    # 4) okayama_data ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®txtãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ -> ãƒ«ãƒ¼ãƒ—ã§2ã¤ç›®ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆãƒ»æ¨è«–
    # ---------------------------------------------------------------------
    step4_start = time.time()
    logger.info("[STEP4] Reading txt files from okayama_data directory ...")

    # okayama_data ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®txtãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
    txt_files = sorted(glob.glob("okayama_data/*.txt"))
    
    print()
    text_4_1 = f"{COLOR_YELLOW}å‡¦ç†ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ•°:{COLOR_RESET} {len(txt_files)}"
    print(text_4_1)
    logger.info(text_4_1)
    print()

    result = []
    make_bool_flase_list = []

    elapsed_time_list = []
    for idx, txt_file in enumerate(txt_files):
        iter_start_time = time.time()

        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ‚£è€…IDã‚’æŠ½å‡º (okayama_001_... -> okayama_001)
        file_basename = os.path.basename(txt_file)
        patient_id = file_basename.split('_')[0] + '_' + file_basename.split('_')[1]
        
        # txtãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã¿è¾¼ã¿
        with open(txt_file, 'r', encoding='utf-8') as f:
            txt_content = f.read()
        
        str_one_document = make_document_text(txt_content)

        # JSON parsing retry logic (æœ€å¤§5å›ã¾ã§)
        max_retries = 5
        retry_count = 0
        json_parse_success = False
        retry_info = ""
        
        while retry_count < max_retries and not json_parse_success:
            retry_count += 1
            
            chat_second = build_second_prompt(structured_question=response1, document_text=str_one_document, retry_info=retry_info)
            response2_raw = run_inference(model, tokenizer, chat_second, temp=0.0, top_p=1.0)
            response2 = extract_text_before_endoftext(response2_raw)

            parsed_json = extract_json_from_response(response2)
            json_parse_success = ("error" not in parsed_json)
            
            if not json_parse_success and retry_count < max_retries:
                retry_info = f"ã€é‡è¦ã€‘å‰å›ã®å¿œç­”ã§JSONãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆè©¦è¡Œå›æ•°: {retry_count}/{max_retries}ï¼‰ã€‚\nå‰å›ã®ã‚¨ãƒ©ãƒ¼: {parsed_json.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}\n\næ­£ç¢ºãªJSONå½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚å¿…ãš```json ã§å§‹ã¾ã‚Š ``` ã§çµ‚ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å½¢å¼ã€ã¾ãŸã¯å˜ç´”ãªJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ " + "{}" + "ã§å›²ã‚“ã§ãã ã•ã„ã€‚"

        # chat_second_str = json.dumps(chat_second, ensure_ascii=False, indent=2)
        # print(f"chat_second_str: \n----------\nğŸ{chat_second_str}ğŸ\n----------")
        # print(f"response2_raw: \n----------\nğŸ{response2_raw}ğŸ\n----------")
        # print(f"response2: \n----------\nğŸ{response2}ğŸ\n----------")
        # print(f"parsed_json: \n----------\nğŸ{parsed_json}ğŸ\n----------")
        # print(f"json_parse_success: \n----------\nğŸ{json_parse_success}ğŸ\n----------")
        # exit()

        try:
            bool_list = []
            for key in parsed_json.keys():
                val = parsed_json[key]
                if isinstance(val, dict) and ("value" in val):
                    bool_list.append(val["value"])
                elif isinstance(val, bool):
                    bool_list.append(val)
                else:
                    bool_list.append(False)

            result_all_true = check_all_true(bool_list)
        except Exception:
            make_bool_flase_list.append([idx, patient_id])
            print(f"ğŸ{parsed_json}ğŸ")
            continue

        print(f"{COLOR_BLUE}--- [Iteration {idx+1}/{len(txt_files)}] ãƒ•ã‚¡ã‚¤ãƒ«: {patient_id} processed ---{COLOR_RESET}")
        parse_success_msg = f"{COLOR_GREEN}SUCCESS{COLOR_RESET}" if json_parse_success else f"{COLOR_RED}FAILED{COLOR_RESET}"
        retry_msg = f" ({retry_count}å›ç›®ã§æˆåŠŸ)" if json_parse_success and retry_count > 1 else f" ({retry_count}å›è©¦è¡Œå¾Œå¤±æ•—)" if not json_parse_success else ""
        print(f"{COLOR_YELLOW}json_parse_success:{COLOR_RESET} {parse_success_msg}{retry_msg}")
        output_str = f"{COLOR_YELLOW}ğŸcheck_all_true ã®çµæœ:{COLOR_RESET} {bool_list} -> {result_all_true}"
        print(output_str)

        logger.info(f"[Iteration {idx+1}/{len(txt_files)}] response2: ğŸ{response2}ğŸ")
        logger.info(f"[Iteration {idx+1}/{len(txt_files)}] parsed_json: ğŸ{parsed_json}ğŸ")
        logger.info(f"[Iteration {idx+1}/{len(txt_files)}] JSON parse success => ğŸ{json_parse_success}ğŸ")
        logger.info(f"[Iteration {idx+1}/{len(txt_files)}] Retry count => ğŸ{retry_count}ğŸ")
        logger.info(f"[Iteration {idx+1}/{len(txt_files)}] check_all_true => ğŸ{output_str}ğŸ")

        iter_end_time = time.time()
        elapsed_time = iter_end_time - iter_start_time
        elapsed_time_list.append(elapsed_time)
        logger.info(f"[Iteration {idx+1}/{len(txt_files)}] took {elapsed_time:.2f} sec, average {sum(elapsed_time_list)/len(elapsed_time_list):.2f} sec\n")
        print(f"{COLOR_BLUE}Took {elapsed_time:.2f} sec, average {sum(elapsed_time_list)/len(elapsed_time_list):.2f} sec{COLOR_RESET}")

        # çµæœã‚’æ ¼ç´
        result.append((
            patient_id,
            txt_file,
            response2,
            parsed_json,
            bool_list[0] if len(bool_list) > 0 else False,
            bool_list[1] if len(bool_list) > 1 else False,
            result_all_true,
            json_parse_success,
            retry_count
        ))

        # æ¯å›result_dfã‚’ä¿å­˜
        result_df = pd.DataFrame(
            result,
            columns=[
                "patient_id",
                "txt_file",
                "response2",
                "parsed_json",
                "bool_list_0",
                "bool_list_1",
                "result_all_true",
                "json_parse_success",
                "retry_count",
            ],
        )
        result_df.to_csv(f"{LOG_DIR}/result_df.csv", index=False)

        # break  # <- å¿…è¦ã«å¿œã˜ã¦ãƒ«ãƒ¼ãƒ—ã‚’é€”ä¸­ã§åˆ‡ã‚ŠãŸã„å ´åˆã«ä½¿ç”¨

    step4_end = time.time()
    logger.info(f"[STEP4] All loop done in {step4_end - step4_start:.3f} seconds\n")

    total_end_time = time.time()
    logger.info(f"=== TOTAL processing time: {total_end_time - total_start_time:.3f} seconds ===")
    logger.info("===== END MAIN =====\n")

    make_bool_flase_df = pd.DataFrame(make_bool_flase_list, columns=["idx", "patient_id"])
    make_bool_flase_df.to_csv(f"{LOG_DIR}/make_bool_flase_df.csv", index=False)

    print(f"{COLOR_GREEN}=== å…¨ä½“å‡¦ç†æ™‚é–“: {(total_end_time - total_start_time)/60:.2f} åˆ† ==={COLOR_RESET}")


if __name__ == "__main__":
    global LABEL
    global LOG_DIR
    global LOG_FILENAME
    global MODEL_PATH

    parser = argparse.ArgumentParser(description="ãƒ©ãƒ™ãƒ«ã‚’æŒ‡å®šã—ã¦å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    parser.add_argument('--label1', type=str, required=True, help="ç–¾æ‚£ã®ãƒ©ãƒ™ãƒ«")
    parser.add_argument('--label2', type=str, required=True, help="å‡¦ç½®ã®ãƒ©ãƒ™ãƒ«")
    args = parser.parse_args()
    LABEL = {"ç–¾æ‚£": args.label1, "å‡¦ç½®": args.label2}
    print(f"{COLOR_RED}LABEL: {LABEL}{COLOR_RESET}")

    # ---------------------
    # è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    # ---------------------
    MODEL_PATH = "../../convert2mlx/calm3-22b-chat-mlx-16bit"
    
    datetime_str = datetime.now().strftime("%Y%m%d%H%M%S")
    
    # Extract model name from MODEL_PATH for folder structure
    model_name = os.path.basename(MODEL_PATH)
    
    LOG_DIR = f"logs/{model_name}/log_{datetime_str}_calm3-22b-16bit_{LABEL['ç–¾æ‚£']}+{LABEL['å‡¦ç½®']}"
    os.makedirs(LOG_DIR, exist_ok=True)

    LOG_FILENAME = datetime.now().strftime(f"{LOG_DIR}/log.txt")

    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)

    file_handler = logging.FileHandler(LOG_FILENAME, mode="w", encoding="utf-8")
    file_handler.setLevel(logging.INFO)
    logger.addHandler(file_handler)

    main()
